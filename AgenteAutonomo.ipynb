{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Construção de agentes autônomos\n",
        "\n",
        "Esta é uma implementação mínima de um agente autônomo que pode pesquisar no Arxiv por artigos relevantes e resumir as ideias centrais do artigo com base na pergunta de pesquisa do usuário.\n",
        "\n",
        "Criaremos apenas uma versão altamente abstrata, na qual LangChain faz toda a orquestração sob o capô.\n",
        "\n"
      ],
      "metadata": {
        "id": "3QttIbUKJgcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalar pacotes e configurar o ambiente"
      ],
      "metadata": {
        "id": "SnlVqqHNKDNh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ShGS9PSJdji",
        "outputId": "4fb67a2a-7391-4940-d109-ffc66dbbe7ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.186)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arxiv in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.10/dist-packages (from arxiv) (6.0.10)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser->arxiv) (1.0.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.7)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install arxiv\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\" "
      ],
      "metadata": {
        "id": "hlJRJ7WeKLwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- importar pacotes necessários"
      ],
      "metadata": {
        "id": "PpnjJuekILUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.agents import Tool\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.utilities import ArxivAPIWrapper"
      ],
      "metadata": {
        "id": "_emlbCkiKZmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Definimos a ferramenta que o modelo de linguagem pode usar: arxiv api (para procurar artigos relevantes), incluindo o nome e as descrições da ferramenta, para que o LLM saiba que pode usar a ferramenta quando necessário"
      ],
      "metadata": {
        "id": "-HYsMV_bHyfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0) # Inicialize o LLM para ser usado\n",
        "arxiv = ArxivAPIWrapper()\n",
        "arxiv_tool = Tool(\n",
        "    name=\"arxiv_search\",\n",
        "    description=\"Search on arxiv. The tool can search a keyword on arxiv for the top papers. It will return publishing date, title, authors, and summary of the papers.\",\n",
        "    func=arxiv.run\n",
        ")\n",
        "\n",
        "tools = [arxiv_tool]"
      ],
      "metadata": {
        "id": "OcXCmWJsMPjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Em seguida, inicializamos o agente passando as ferramentas e o modelo LLM"
      ],
      "metadata": {
        "id": "7CcwxM30H8yQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "_UCZr8y7H5Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Por fim, fazemos uma pergunta ao agente. O agente usará a estrutura ReAct para concluir a tarefa. Ele primeiro pensa se tem todas as informações necessárias, então decide usar a API do arxiv para procurar artigos relevantes, quando obtém os artigos, resume o conteúdo e os devolve ao usuário."
      ],
      "metadata": {
        "id": "Ns67k7wGHYpg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(\"What is a Large Language Model ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "id": "qX4PpHxCHftg",
        "outputId": "d37c802b-bc7e-4a44-bffb-d82a2ee3f454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should use arxiv_search to find papers that define and explain Large Language Models.\n",
            "Action: arxiv_search\n",
            "Action Input: \"Large Language Model\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPublished: 2022-02-07\n",
            "Title: Cedille: A large autoregressive French language model\n",
            "Authors: Martin Müller, Florian Laurent\n",
            "Summary: Scaling up the size and training of autoregressive language models has\n",
            "enabled novel ways of solving Natural Language Processing tasks using zero-shot\n",
            "and few-shot learning. While extreme-scale language models such as GPT-3 offer\n",
            "multilingual capabilities, zero-shot learning for languages other than English\n",
            "remain largely unexplored. Here, we introduce Cedille, a large open source\n",
            "auto-regressive language model, specifically trained for the French language.\n",
            "Our results show that Cedille outperforms existing French language models and\n",
            "is competitive with GPT-3 on a range of French zero-shot benchmarks.\n",
            "Furthermore, we provide an in-depth comparison of the toxicity exhibited by\n",
            "these models, showing that Cedille marks an improvement in language model\n",
            "safety thanks to dataset filtering.\n",
            "\n",
            "Published: 2023-05-11\n",
            "Title: How Good are Commercial Large Language Models on African Languages?\n",
            "Authors: Jessica Ojo, Kelechi Ogueji\n",
            "Summary: Recent advancements in Natural Language Processing (NLP) has led to the\n",
            "proliferation of large pretrained language models. These models have been shown\n",
            "to yield good performance, using in-context learning, even on unseen tasks and\n",
            "languages. They have also been exposed as commercial APIs as a form of\n",
            "language-model-as-a-service, with great adoption. However, their performance on\n",
            "African languages is largely unknown. We present a preliminary analysis of\n",
            "commercial large language models on two tasks (machine translation and text\n",
            "classification) across eight African languages, spanning different language\n",
            "families and geographical areas. Our results suggest that commercial language\n",
            "models produce below-par performance on African languages. We also find that\n",
            "they perform better on text classification than machine translation. In\n",
            "general, our findings present a call-to-action to ensure African languages are\n",
            "well represented in commercial large language models, given their growing\n",
            "popularity.\n",
            "\n",
            "Published: 2022-05-16\n",
            "Title: A Precis of Language Models are not Models of Language\n",
            "Authors: Csaba Veres\n",
            "Summary: Natural Language Processing is one of the leading application areas in the\n",
            "current resurgence of Artificial Intelligence, spearheaded by Artificial Neural\n",
            "Networks. We show that despite their many successes at performing linguistic\n",
            "tasks, Large Neural Language Models are ill-suited as comprehensive models of\n",
            "natural language. The wider implication is that, in spite of the often\n",
            "overbearing optimism about AI, modern neural models do not represent a\n",
            "revolution in our understanding of cognition.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mBased on the papers found, Large Language Models are autoregressive language models that have been scaled up in size and training to enable novel ways of solving Natural Language Processing tasks using zero-shot and few-shot learning. However, their performance on African languages is largely unknown and they may not be comprehensive models of natural language. \n",
            "Final Answer: Large Language Models are autoregressive language models that have been scaled up in size and training to enable novel ways of solving Natural Language Processing tasks using zero-shot and few-shot learning, but their performance on African languages is largely unknown and they may not be comprehensive models of natural language.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Large Language Models are autoregressive language models that have been scaled up in size and training to enable novel ways of solving Natural Language Processing tasks using zero-shot and few-shot learning, but their performance on African languages is largely unknown and they may not be comprehensive models of natural language.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}